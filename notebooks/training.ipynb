{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44d7202-0ab7-4f39-9302-9e796776b708",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f2250cb-4f8a-4505-a7ad-3e364ac75d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6f069-a708-411d-85bb-2b83e3efad09",
   "metadata": {},
   "source": [
    "### Importing Classic ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63573844-8c84-4364-ac0e-7df2c742efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5a08d-f4a7-4425-9d79-01abb2c4ab37",
   "metadata": {},
   "source": [
    "## 2. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6cb9aa3-c3f2-48f4-adff-403c4757f400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data loaded successfully.\n",
      "        age  trestbps      chol   thalach   oldpeak  sex_1  cp_1  cp_2  cp_3  \\\n",
      "0 -0.267966 -0.376556 -0.667728  0.806035 -0.037124    1.0   0.0   0.0   0.0   \n",
      "1 -0.157260  0.478910 -0.841918  0.237495  1.773958    1.0   0.0   0.0   0.0   \n",
      "2  1.724733  0.764066 -1.403197 -1.074521  1.342748    1.0   0.0   0.0   0.0   \n",
      "3  0.728383  0.935159 -0.841918  0.499898 -0.899544    1.0   0.0   0.0   0.0   \n",
      "4  0.839089  0.364848  0.919336 -1.905464  0.739054    0.0   0.0   0.0   0.0   \n",
      "\n",
      "   fbs_1  ...  slope_1  slope_2  ca_1  ca_2  ca_3  ca_4  thal_1  thal_2  \\\n",
      "0    0.0  ...      0.0      1.0   0.0   1.0   0.0   0.0     0.0     0.0   \n",
      "1    1.0  ...      0.0      0.0   0.0   0.0   0.0   0.0     0.0     0.0   \n",
      "2    0.0  ...      0.0      0.0   0.0   0.0   0.0   0.0     0.0     0.0   \n",
      "3    0.0  ...      0.0      1.0   1.0   0.0   0.0   0.0     0.0     0.0   \n",
      "4    1.0  ...      1.0      0.0   0.0   0.0   1.0   0.0     0.0     1.0   \n",
      "\n",
      "   thal_3  target  \n",
      "0     1.0       0  \n",
      "1     1.0       0  \n",
      "2     1.0       0  \n",
      "3     1.0       0  \n",
      "4     0.0       0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_csv('../data/processed/cleaned_data.csv')\n",
    "    print(\"Processed data loaded successfully.\")\n",
    "    print(data.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'cleaned_data.csv' not found in 'data/processed/'.\")\n",
    "    print(\"Please ensure you have run the preprocessing script first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ba3b6-2d31-4fa2-af46-978d52737c3a",
   "metadata": {},
   "source": [
    "## 3. Seperating Features and Target & Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26874c10-7b53-4547-8c6d-92b8fa3adb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (241, 22)\n",
      "Testing set shape: (61, 22)\n"
     ]
    }
   ],
   "source": [
    "X= data.drop('target', axis=1)\n",
    "y= data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720de0a6-99b0-4ab1-9af5-c92706069f13",
   "metadata": {},
   "source": [
    "## 4. Model Development & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bd59804-95f5-4327-bf6e-f94566ede88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.8524590163934426\n",
      "Precision: 0.875\n",
      "Recall: 0.8484848484848485\n",
      "F1-Score: 0.8615384615384616\n",
      "\n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy: 0.8032786885245902\n",
      "Precision: 0.8620689655172413\n",
      "Recall: 0.7575757575757576\n",
      "F1-Score: 0.8064516129032258\n",
      "\n",
      "\n",
      "Model: Support Vector MAchine\n",
      "Accuracy: 0.8032786885245902\n",
      "Precision: 0.8620689655172413\n",
      "Recall: 0.7575757575757576\n",
      "F1-Score: 0.8064516129032258\n",
      "\n",
      "\n",
      "Model: Naive Bayes\n",
      "Accuracy: 0.8524590163934426\n",
      "Precision: 0.8529411764705882\n",
      "Recall: 0.8787878787878788\n",
      "F1-Score: 0.8656716417910447\n",
      "\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.6557377049180327\n",
      "Precision: 0.6764705882352942\n",
      "Recall: 0.696969696969697\n",
      "F1-Score: 0.6865671641791045\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praja\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\praja\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\praja\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\praja\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\praja\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Accuracy: 0.819672131147541\n",
      "Precision: 0.84375\n",
      "Recall: 0.8181818181818182\n",
      "F1-Score: 0.8307692307692308\n",
      "\n",
      "\n",
      "Model: Grandient Boosting\n",
      "Accuracy: 0.7704918032786885\n",
      "Precision: 0.8064516129032258\n",
      "Recall: 0.7575757575757576\n",
      "F1-Score: 0.78125\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Accuracy: 0.7704918032786885\n",
      "Precision: 0.8275862068965517\n",
      "Recall: 0.7272727272727273\n",
      "F1-Score: 0.7741935483870968\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models ={\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector MAchine\": SVC(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Grandient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred= model.predict(X_test)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"F1-Score: {f1_score(y_test, y_pred)}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
