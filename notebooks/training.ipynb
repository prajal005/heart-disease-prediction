{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44d7202-0ab7-4f39-9302-9e796776b708",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f2250cb-4f8a-4505-a7ad-3e364ac75d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6f069-a708-411d-85bb-2b83e3efad09",
   "metadata": {},
   "source": [
    "### Importing Classic ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63573844-8c84-4364-ac0e-7df2c742efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5a08d-f4a7-4425-9d79-01abb2c4ab37",
   "metadata": {},
   "source": [
    "## 2. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6cb9aa3-c3f2-48f4-adff-403c4757f400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data loaded successfully.\n",
      "        age  trestbps      chol   thalach   oldpeak  sex_1  cp_1  cp_2  cp_3  \\\n",
      "0 -0.267966 -0.376556 -0.667728  0.806035 -0.037124    1.0   0.0   0.0   0.0   \n",
      "1 -0.157260  0.478910 -0.841918  0.237495  1.773958    1.0   0.0   0.0   0.0   \n",
      "2  1.724733  0.764066 -1.403197 -1.074521  1.342748    1.0   0.0   0.0   0.0   \n",
      "3  0.728383  0.935159 -0.841918  0.499898 -0.899544    1.0   0.0   0.0   0.0   \n",
      "4  0.839089  0.364848  0.919336 -1.905464  0.739054    0.0   0.0   0.0   0.0   \n",
      "\n",
      "   fbs_1  ...  slope_1  slope_2  ca_1  ca_2  ca_3  ca_4  thal_1  thal_2  \\\n",
      "0    0.0  ...      0.0      1.0   0.0   1.0   0.0   0.0     0.0     0.0   \n",
      "1    1.0  ...      0.0      0.0   0.0   0.0   0.0   0.0     0.0     0.0   \n",
      "2    0.0  ...      0.0      0.0   0.0   0.0   0.0   0.0     0.0     0.0   \n",
      "3    0.0  ...      0.0      1.0   1.0   0.0   0.0   0.0     0.0     0.0   \n",
      "4    1.0  ...      1.0      0.0   0.0   0.0   1.0   0.0     0.0     1.0   \n",
      "\n",
      "   thal_3  target  \n",
      "0     1.0       0  \n",
      "1     1.0       0  \n",
      "2     1.0       0  \n",
      "3     1.0       0  \n",
      "4     0.0       0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_csv('../data/processed/cleaned_data.csv')\n",
    "    print(\"Processed data loaded successfully.\")\n",
    "    print(data.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'cleaned_data.csv' not found in 'data/processed/'.\")\n",
    "    print(\"Please ensure you have run the preprocessing script first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ba3b6-2d31-4fa2-af46-978d52737c3a",
   "metadata": {},
   "source": [
    "## 3. Seperating Features and Target & Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26874c10-7b53-4547-8c6d-92b8fa3adb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (241, 22)\n",
      "Testing set shape: (61, 22)\n"
     ]
    }
   ],
   "source": [
    "X= data.drop('target', axis=1)\n",
    "y= data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720de0a6-99b0-4ab1-9af5-c92706069f13",
   "metadata": {},
   "source": [
    "## 4. Model Development & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea1aabf8-82b1-47ce-877b-cd31a406579d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Confusion Matrix:\n",
      "[[24  4]\n",
      " [ 5 28]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84        28\n",
      "           1       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n",
      "\n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Confusion Matrix:\n",
      "[[24  4]\n",
      " [ 8 25]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80        28\n",
      "           1       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.80        61\n",
      "   macro avg       0.81      0.81      0.80        61\n",
      "weighted avg       0.81      0.80      0.80        61\n",
      "\n",
      "\n",
      "\n",
      "Model: Support Vector MAchine\n",
      "Confusion Matrix:\n",
      "[[24  4]\n",
      " [ 8 25]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80        28\n",
      "           1       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.80        61\n",
      "   macro avg       0.81      0.81      0.80        61\n",
      "weighted avg       0.81      0.80      0.80        61\n",
      "\n",
      "\n",
      "\n",
      "Model: Naive Bayes\n",
      "Confusion Matrix:\n",
      "[[23  5]\n",
      " [ 4 29]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84        28\n",
      "           1       0.85      0.88      0.87        33\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n",
      "\n",
      "\n",
      "Model: Decision Tree\n",
      "Confusion Matrix:\n",
      "[[17 11]\n",
      " [10 23]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62        28\n",
      "           1       0.68      0.70      0.69        33\n",
      "\n",
      "    accuracy                           0.66        61\n",
      "   macro avg       0.65      0.65      0.65        61\n",
      "weighted avg       0.65      0.66      0.66        61\n",
      "\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Confusion Matrix:\n",
      "[[23  5]\n",
      " [ 6 27]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81        28\n",
      "           1       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.82        61\n",
      "   macro avg       0.82      0.82      0.82        61\n",
      "weighted avg       0.82      0.82      0.82        61\n",
      "\n",
      "\n",
      "\n",
      "Model: Grandient Boosting\n",
      "Confusion Matrix:\n",
      "[[22  6]\n",
      " [ 8 25]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76        28\n",
      "           1       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.77        61\n",
      "   macro avg       0.77      0.77      0.77        61\n",
      "weighted avg       0.77      0.77      0.77        61\n",
      "\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Confusion Matrix:\n",
      "[[23  5]\n",
      " [ 9 24]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77        28\n",
      "           1       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.77        61\n",
      "   macro avg       0.77      0.77      0.77        61\n",
      "weighted avg       0.78      0.77      0.77        61\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models ={\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector MAchine\": SVC(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Grandient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred= model.predict(X_test)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bd59804-95f5-4327-bf6e-f94566ede88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.8524590163934426\n",
      "Precision: 0.875\n",
      "Recall: 0.8484848484848485\n",
      "F1-Score: 0.8615384615384616\n",
      "\n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy: 0.8032786885245902\n",
      "Precision: 0.8620689655172413\n",
      "Recall: 0.7575757575757576\n",
      "F1-Score: 0.8064516129032258\n",
      "\n",
      "\n",
      "Model: Support Vector MAchine\n",
      "Accuracy: 0.8032786885245902\n",
      "Precision: 0.8620689655172413\n",
      "Recall: 0.7575757575757576\n",
      "F1-Score: 0.8064516129032258\n",
      "\n",
      "\n",
      "Model: Naive Bayes\n",
      "Accuracy: 0.8524590163934426\n",
      "Precision: 0.8529411764705882\n",
      "Recall: 0.8787878787878788\n",
      "F1-Score: 0.8656716417910447\n",
      "\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.6557377049180327\n",
      "Precision: 0.6764705882352942\n",
      "Recall: 0.696969696969697\n",
      "F1-Score: 0.6865671641791045\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.819672131147541\n",
      "Precision: 0.84375\n",
      "Recall: 0.8181818181818182\n",
      "F1-Score: 0.8307692307692308\n",
      "\n",
      "\n",
      "Model: Grandient Boosting\n",
      "Accuracy: 0.7704918032786885\n",
      "Precision: 0.8064516129032258\n",
      "Recall: 0.7575757575757576\n",
      "F1-Score: 0.78125\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Accuracy: 0.7704918032786885\n",
      "Precision: 0.8275862068965517\n",
      "Recall: 0.7272727272727273\n",
      "F1-Score: 0.7741935483870968\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models ={\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector MAchine\": SVC(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Grandient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred= model.predict(X_test)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"F1-Score: {f1_score(y_test, y_pred)}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
